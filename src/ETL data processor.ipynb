{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/davidmarip/DS2002-PROJECT/blob/main/DataProject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "7UkPTyZkHzKS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "#Resources we used:\n",
    "#https://www.geeksforgeeks.org/what-is-etl-extract-transform-load/\n",
    "#https://aws.amazon.com/what-is/etl/\n",
    "#https://stackoverflow.com/questions/71004420/trying-to-read-json-from-url-and-parse-into-csv-format\n",
    "#https://www.geeksforgeeks.org/save-api-data-into-csv-format-using-python/\n",
    "#https://www.sqlitetutorial.net/sqlite-python/insert/\n",
    "#https://pythonforthelab.com/blog/storing-data-with-sqlite/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ujI_anrcmMpx"
   },
   "outputs": [],
   "source": [
    "def load_input_data(input_file, input_format):\n",
    "    try:\n",
    "        if input_format == 'csv':\n",
    "            return pd.read_csv(input_file)\n",
    "        elif input_format == 'json':\n",
    "            with open(input_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                return pd.json_normalize(data)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported input format. Choose 'csv' or 'json'.\")\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"File {input_file} not found: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise ValueError(f\"Error decoding JSON: {e}\")\n",
    "\n",
    "    \n",
    "#loads data either from CSV or JSON, and converts the JSON data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GnAPViA40N5U"
   },
   "outputs": [],
   "source": [
    "def modify_columns(data, keep_columns=None, add_columns=None, remove_columns=None):\n",
    "    # Check if columns exist before modifying\n",
    "    if keep_columns:\n",
    "        missing_keep = [col for col in keep_columns if col not in data.columns]\n",
    "        if missing_keep:\n",
    "            raise ValueError(f\"Columns to keep not found: {missing_keep}\")\n",
    "        data = data[keep_columns]\n",
    "\n",
    "    if add_columns:\n",
    "        for column, value in add_columns.items():\n",
    "            data[column] = value\n",
    "\n",
    "    if remove_columns:\n",
    "        missing_remove = [col for col in remove_columns if col not in data.columns]\n",
    "        if missing_remove:\n",
    "            raise ValueError(f\"Columns to remove not found: {missing_remove}\")\n",
    "        data = data.drop(columns=remove_columns)\n",
    "\n",
    "    return data\n",
    "\n",
    "# to keep, add, or drop specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Q16rEdX14m2S"
   },
   "outputs": [],
   "source": [
    "def convert_and_save(data, output_file, output_format, db_table=None, db_file=None):\n",
    "\n",
    "    if output_format == 'csv':\n",
    "        data.to_csv(output_file, index=False)\n",
    "        print(f\"Data saved as CSV to {output_file}\")\n",
    "    elif output_format == 'json':\n",
    "        data_json = data.to_json(orient='records', indent=4)\n",
    "        with open(output_file, 'w') as f:\n",
    "            f.write(data_json)\n",
    "        print(f\"Data saved as JSON to {output_file}\")\n",
    "    elif output_format == 'sqlite':\n",
    "        if db_file is None or db_table is None:\n",
    "            raise ValueError(\"For SQL output, specify both db_file and db_table.\")\n",
    "        conn = sqlite3.connect(db_file)  # Use db_file, not output_file\n",
    "        try:\n",
    "            data.to_sql(db_table, conn, if_exists='replace', index=False)\n",
    "            print(f\"Data saved to SQLite table '{db_table}' in database {db_file}\")\n",
    "        finally:\n",
    "            conn.close()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported output format. Choose 'csv', 'json', or 'sqlite'.\")\n",
    "\n",
    "#convert the data format (CSV, Json, or SQL) to the desired output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pGVRSEHp6wa4"
   },
   "outputs": [],
   "source": [
    "def store_data(data, output_format, output_file, db_table=None, db_file=None):\n",
    "  convert_and_save(data, output_file, output_format, db_table, db_file)\n",
    "\n",
    "#function to store the data in SQl or write to disk (as CSV or Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "lLfFnImREdZj"
   },
   "outputs": [],
   "source": [
    "def view_sql_data(db_file, db_table):\n",
    "    conn = sqlite3.connect(db_file)\n",
    "    query = f\"SELECT * FROM {db_table}\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "17zricjmEkA6"
   },
   "outputs": [],
   "source": [
    "def etl_processor(input_file, input_format='csv', output_format='csv',\n",
    "                  output_file='output_data', keep_columns=None, add_columns=None, remove_columns=None,\n",
    "                  db_table=None, db_file=None):\n",
    "    data = load_input_data(input_file, input_format)\n",
    "    modified_data = modify_columns(data, keep_columns, add_columns, remove_columns)\n",
    "    store_data(modified_data, output_format, output_file, db_table, db_file)\n",
    "    return modified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNQuTA_vzRlP"
   },
   "source": [
    "The Input CSV file, US_Census_Tract_Area_2010.csv, is mounted through a local file. It's from Charlottesville open data with information about specific demographics. It contains 12 records and 353 columns of multiple demographic attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "28w7d49z-r2Y",
    "outputId": "2a34acb2-44ec-41af-91b5-c88f09b16409"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as JSON to transformed_US2010census_data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AREA_</th>\n",
       "      <th>Population</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>AmIndian</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Hawaiian</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9011</td>\n",
       "      <td>1.186296</td>\n",
       "      <td>4675</td>\n",
       "      <td>3505</td>\n",
       "      <td>706</td>\n",
       "      <td>3</td>\n",
       "      <td>180</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9030</td>\n",
       "      <td>0.474023</td>\n",
       "      <td>3305</td>\n",
       "      <td>1253</td>\n",
       "      <td>1708</td>\n",
       "      <td>21</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9047</td>\n",
       "      <td>0.374655</td>\n",
       "      <td>4351</td>\n",
       "      <td>2681</td>\n",
       "      <td>355</td>\n",
       "      <td>2</td>\n",
       "      <td>1087</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9065</td>\n",
       "      <td>0.639455</td>\n",
       "      <td>3324</td>\n",
       "      <td>1471</td>\n",
       "      <td>1588</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9084</td>\n",
       "      <td>0.370543</td>\n",
       "      <td>5617</td>\n",
       "      <td>3936</td>\n",
       "      <td>1097</td>\n",
       "      <td>12</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID     AREA_  Population  White  Black  AmIndian  Asian  Hawaiian  Other\n",
       "0  9011  1.186296        4675   3505    706         3    180         2    130\n",
       "1  9030  0.474023        3305   1253   1708        21    135         0     80\n",
       "2  9047  0.374655        4351   2681    355         2   1087         1     55\n",
       "3  9065  0.639455        3324   1471   1588         7     44         0    122\n",
       "4  9084  0.370543        5617   3936   1097        12    339         3     59"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = '/Users/davidmarip/Downloads/DS2002/US_Census_Tract_Area_2010.csv'  #file path VARIES BY DEVICE LOCAL STORAGE!\n",
    "transformed_US2010census_data = etl_processor(\n",
    "    input_file=input_file,\n",
    "    input_format='csv',  # Input file format\n",
    "    output_format='json',  # Desired output format ('csv', 'json', 'sql')\n",
    "    output_file='transformed_US2010census_data',  # Base name for output file\n",
    "    keep_columns=['ID','AREA_','Population','White','Black', 'AmIndian', 'Asian', 'Hawaiian', 'Other'],  # Columns to keep\n",
    "    add_columns=None,\n",
    "    remove_columns=None,\n",
    "    db_table='input_file',  # For SQL output\n",
    "    db_file='database.db'  # SQLite database for SQL output\n",
    ")\n",
    "df = pd.read_json('transformed_US2010census_data')\n",
    "df.head()\n",
    "# Example Usage for US_Census_Tract_Area_2010 for Charlottesville\n",
    "# takes inputted cvs file and transforms (keeps columns ObjectID, ID, Area, Population, White, and Black)\n",
    "# output formatted as Json saved to transformed_US2010census_data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6BeswrXNap1X",
    "outputId": "4657e4a9-87ad-495a-d8c1-66d7260785b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12 entries, 0 to 11\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   ID          12 non-null     int64  \n",
      " 1   AREA_       12 non-null     float64\n",
      " 2   Population  12 non-null     int64  \n",
      " 3   White       12 non-null     int64  \n",
      " 4   Black       12 non-null     int64  \n",
      " 5   AmIndian    12 non-null     int64  \n",
      " 6   Asian       12 non-null     int64  \n",
      " 7   Hawaiian    12 non-null     int64  \n",
      " 8   Other       12 non-null     int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 996.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-a9f5vcaiFZ"
   },
   "source": [
    "The output DataFrame is a transformed version of the US_Census_Tract_Area_2010.csv with 12 Records and only 9 columns. Of these columns includes: ID, AREA_, Population, White, Black, AmIndian, Asian, Hawaiian, Other. It focuses the data to more specific demographics and get's rid of columns such as State and County, which had the same values for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved as CSV to /Users/davidmarip/Downloads/DS2002/airports_transformed.csv\n",
      "Test for JSON to CSV passed\n"
     ]
    }
   ],
   "source": [
    "def test_json_to_csv():\n",
    "    try:\n",
    "        input_file = '/Users/davidmarip/Downloads/DS2002/Airports.json'\n",
    "        output_file = '/Users/davidmarip/Downloads/DS2002/airports_transformed.csv'\n",
    "        \n",
    "        transformed_data = etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='json',\n",
    "            output_format='csv',\n",
    "            output_file=output_file\n",
    "        )\n",
    "        \n",
    "        assert os.path.exists(output_file), \"CSV file was not created\"\n",
    "        print(f\"Test for JSON to CSV passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test for JSON to CSV failed: {e}\")\n",
    "\n",
    "# Call the test function\n",
    "test_json_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting API to CSV test\n",
      "Data saved as CSV to meteorite_transformed.csv\n",
      "Test for NASA API to CSV passed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "#https://www.geeksforgeeks.org/save-api-data-into-csv-format-using-python/\n",
    "\n",
    "def test_api_to_csv():\n",
    "    print(\"Starting API to CSV test\")\n",
    "    try:\n",
    "        # NASA API URL for meteorite landings dataset in JSON format\n",
    "        url = \"https://data.nasa.gov/api/views/gh4g-9sfh/rows.json?accessType=DOWNLOAD\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "\n",
    "        # Save the JSON response to a file\n",
    "        input_file = 'meteorite.json'\n",
    "        with open(input_file, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        \n",
    "        # Convert the JSON to CSV\n",
    "        output_file = 'meteorite_transformed.csv'\n",
    "        transformed_data = etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='json',\n",
    "            output_format='csv',\n",
    "            output_file=output_file\n",
    "        )\n",
    "        \n",
    "        assert os.path.exists(output_file), \"CSV file was not created from API data\"\n",
    "        print(f\"Test for NASA API to CSV passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test for NASA API to CSV failed: {e}\")\n",
    "\n",
    "# Call the function to run the test\n",
    "test_api_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting summary test\n",
      "Pre-processing summary: {'number_of_records': 12, 'number_of_columns': 6}\n",
      "Data saved as CSV to /Users/davidmarip/Downloads/DS2002/market_data_summary.csv\n",
      "Post-processing summary: {'number_of_records': 12, 'number_of_columns': 5}\n",
      "Test for summarizing data passed\n"
     ]
    }
   ],
   "source": [
    "def test_generate_summary():\n",
    "    print(\"Starting summary test\")\n",
    "    try:\n",
    "        input_file = '/Users/davidmarip/Downloads/DS2002/New_Market_Tax_Credit_Eligible_Area_2015.csv'\n",
    "        output_file = '/Users/davidmarip/Downloads/DS2002/market_data_summary.csv'\n",
    "        keep_columns = ['COUNTY', 'TRACT', 'NAME', 'STATUS', 'FIPS']\n",
    "        \n",
    "        # Pre-processing summary\n",
    "        data = pd.read_csv(input_file)\n",
    "        pre_summary = {\n",
    "            'number_of_records': data.shape[0],\n",
    "            'number_of_columns': data.shape[1]\n",
    "        }\n",
    "        print(f\"Pre-processing summary: {pre_summary}\")\n",
    "        \n",
    "        # Run ETL\n",
    "        transformed_data = etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='csv',\n",
    "            output_format='csv',\n",
    "            output_file=output_file,\n",
    "            keep_columns=keep_columns\n",
    "        )\n",
    "        \n",
    "        # Post-processing summary\n",
    "        post_summary = {\n",
    "            'number_of_records': transformed_data.shape[0],\n",
    "            'number_of_columns': transformed_data.shape[1]\n",
    "        }\n",
    "        print(f\"Post-processing summary: {post_summary}\")\n",
    "        assert post_summary['number_of_columns'] == len(keep_columns), \"Column modification failed\"\n",
    "        print(f\"Test for summarizing data passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test for summarizing data failed: {e}\")\n",
    "\n",
    "test_generate_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting missing file test\n",
      "Test for missing file passed\n"
     ]
    }
   ],
   "source": [
    "def test_missing_file():\n",
    "    print(\"Starting missing file test\")\n",
    "    try:\n",
    "        input_file = '/Users/davidmarip/Downloads/DS2002/missing_file.csv'\n",
    "        \n",
    "        etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='csv',\n",
    "            output_format='csv',\n",
    "            output_file='output.csv'\n",
    "        )\n",
    "        print(\"Test for missing file failed: no exception raised\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Test for missing file passed\")\n",
    "\n",
    "test_missing_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting unsupported format test\n",
      "Test for unsupported format passed\n"
     ]
    }
   ],
   "source": [
    "def test_unsupported_format():\n",
    "    print(\"Starting unsupported format test\")\n",
    "    try:\n",
    "        input_file = '/Users/davidmarip/Downloads/DS2002/US_Census_Tract_Area_2010.csv'\n",
    "        \n",
    "        etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='csv',\n",
    "            output_format='xml',  # Unsupported format\n",
    "            output_file='output.xml'\n",
    "        )\n",
    "        print(\"Test for unsupported format failed: no exception raised\")\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"Unsupported output format. Choose 'csv', 'json', or 'sqlite'.\"\n",
    "        print(f\"Test for unsupported format passed\")\n",
    "\n",
    "test_unsupported_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CSV to SQLite test\n",
      "Data saved to SQLite table 'census_data' in database test_census_data.db\n",
      "Test for saving data to SQLite passed\n"
     ]
    }
   ],
   "source": [
    "#https://pythonforthelab.com/blog/storing-data-with-sqlite/\n",
    "#https://pythonforthelab.com/blog/storing-data-with-sqlite/\n",
    "def test_save_to_sqlite():\n",
    "    print(\"Starting CSV to SQLite test\")\n",
    "    try:\n",
    "        input_file = '/Users/davidmarip/Downloads/DS2002/US_Census_Tract_Area_2010.csv'\n",
    "        db_file = 'test_census_data.db'\n",
    "        db_table = 'census_data'\n",
    "        \n",
    "        etl_processor(\n",
    "            input_file=input_file,\n",
    "            input_format='csv',\n",
    "            output_format='sqlite',\n",
    "            output_file=None,\n",
    "            keep_columns=None,\n",
    "            add_columns=None,\n",
    "            remove_columns=None,\n",
    "            db_table=db_table,\n",
    "            db_file=db_file\n",
    "        )\n",
    "        \n",
    "        # Check if the data was written to the SQLite table\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        query = f\"SELECT * FROM {db_table} LIMIT 5\"\n",
    "        result = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        assert not result.empty, \"SQLite table is empty\"\n",
    "        print(f\"Test for saving data to SQLite passed\")\n",
    "    except Exception as e:\n",
    "        print(f\"Test for saving data to SQLite failed: {e}\")\n",
    "\n",
    "test_save_to_sqlite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNr0N1+zu0YKrEFAQosG5dG",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
